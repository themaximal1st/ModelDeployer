{
    "name": "@themaximalist/modeldeployer",
    "version": "0.0.1",
    "description": "Deploy and Manage AI Models",
    "type": "module",
    "main": "src/index.js",
    "scripts": {
        "start": "npm run server",
        "dev": "npm run watch",
        "test": "dotenv-extended mocha",
        "cachebust": "echo $(( $(cat public/cachebust.txt) + 1 )) > public/cachebust.txt",
        "server": "node src/index.js",
        "watch": "nf -j Procfile.dev start",
        "build": "npm run build:css",
        "build:css": "npx tailwindcss -i ./src/app.css -o ./public/app.css",
        "watch:server": "nodemon npm run server",
        "watch:css": "npx tailwindcss -i ./src/app.css -o ./public/app.css --watch"
    },
    "keywords": [
        "ai",
        "llm",
        "llama",
        "gpt-4",
        "deploy",
        "models"
    ],
    "author": "The Maximalist",
    "license": "MIT",
    "devDependencies": {
        "@tailwindcss/forms": "^0.5.7",
        "@tailwindcss/typography": "^0.5.10",
        "@themaximalist/llm.js": "^0.3.5",
        "debug": "^4.3.4",
        "dotenv-extended": "^2.9.0",
        "express": "^4.18.2",
        "foreman": "^3.0.1",
        "nodemon": "^3.0.2",
        "pg": "^8.11.3",
        "sequelize": "^6.35.2",
        "tailwindcss": "^3.4.1"
    }
}
