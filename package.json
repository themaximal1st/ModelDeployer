{
    "name": "@themaximalist/modeldeployer",
    "version": "0.0.8",
    "description": "Deploy and Manage AI Models",
    "type": "module",
    "main": "src/index.js",
    "homepage": "https://modeldeployer.themaximalist.com",
    "repository": {
        "type": "git",
        "url": "git+https://github.com/themaximal1st/modeldeployer.git"
    },
    "scripts": {
        "start": "npm run server",
        "dev": "npm run watch",
        "test": "dotenv-extended mocha",
        "cachebust": "echo $(( $(cat static/cachebust.txt) + 1 )) > static/cachebust.txt",
        "server": "node src/index.js",
        "watch": "nf -j Procfile.dev start",
        "build": "npm run build:css",
        "build:css": "npx tailwindcss -i ./src/app.css -o ./static/app.css",
        "watch:server": "nodemon npm run server",
        "watch:css": "npx tailwindcss -i ./src/app.css -o ./static/app.css --watch"
    },
    "keywords": [
        "ai",
        "llm",
        "llama",
        "gpt-4",
        "deploy",
        "models"
    ],
    "author": "The Maximalist",
    "license": "MIT",
    "devDependencies": {
        "@tailwindcss/forms": "^0.5.7",
        "@tailwindcss/typography": "^0.5.10",
        "@themaximalist/embeddings.js": "^0.0.4",
        "@themaximalist/hummingbird.js": "^0.0.4",
        "@themaximalist/llm.js": "^0.4.7",
        "bcrypt": "^5.1.1",
        "debug": "^4.3.4",
        "dotenv-extended": "^2.9.0",
        "express": "^4.18.2",
        "foreman": "^3.0.1",
        "install": "^0.13.0",
        "js-tiktoken": "^1.0.8",
        "lodash": "^4.17.21",
        "nodemon": "^3.0.2",
        "npm": "^10.2.5",
        "pg": "^8.11.3",
        "relative-time-format": "^1.1.6",
        "sequelize": "^6.35.2",
        "tailwindcss": "^3.4.1"
    },
    "peerDependencies": {
        "@xenova/transformers": "^2.14.0"
    },
    "peerDependenciesMeta": {
        "@xenova/transformers": {
            "optional": true
        }
    }
}
